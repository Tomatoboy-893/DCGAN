
本プロジェクトの Generator は、**DCGAN (Deep Convolutional GAN)** のアーキテクチャを採用しており、100次元の乱数（ノイズ）を入力として、32x32ピクセルの手書き数字画像を生成している。

### アーキテクチャ概要
Generatorは、**転置畳み込み (Transposed Convolution)** を用いて、特徴マップのサイズを段階的に拡大（アップサンプリング）していく構造になっている。

1.  **入力**: 100次元の潜在変数 $z$ (正規分布ノイズ)
2.  **層の構成**: 全4層のアップサンプリング
    -   入力 $\rightarrow$ $4 \times 4$
    -   $4 \times 4$ $\rightarrow$ $8 \times 8$
    -   $8 \times 8$ $\rightarrow$ $16 \times 16$
    -   $16 \times 16$ $\rightarrow$ $32 \times 32$ (出力画像)
3.  **出力**: $1 \times 32 \times 32$ のグレースケール画像 (値の範囲は $[-1, 1]$)

### 実装のポイント
-   **ConvTranspose2d (逆畳み込み)**:
    通常の畳み込み（画像サイズを小さくする）とは逆に、画像サイズを倍々に拡大しながら特徴を学習している。
-   **Batch Normalization**:
    各層の出力の分布を整えることで、学習を安定させ、勾配消失や初期値依存の問題を軽減している。
-   **活性化関数**:
    -   中間層: **ReLU** (Rectified Linear Unit) を使用し、スパースな表現を学習させている。
    -   出力層: **Tanh** (Hyperbolic Tangent) を使用。これは、Discriminatorへの入力画像が `[-1, 1]` に正規化されているため、出力範囲を合わせるために必須である。

### なぜ 32x32 なのか？
MNISTの元データは $28 \times 28$ ですが、本モデルでは $32 \times 32$ にリサイズして扱っている。
これは、CNNの構造上、サイズを $2$ の累乗（$4 \to 8 \to 16 \to 32$）で変化させる方が、パディング計算が容易でモデル構造がシンプルになるため。


## 実行結果 (Results)

本プロジェクトによる学習・生成結果の一例です。

### 1. 手書き数字の生成 (Task 1)
学習が進むにつれて、ノイズから意味のある数字が形成されます。以下は20エポック学習後の生成画像。
「0」から「9」までの数字が、多様な筆跡で生成されていることが確認できる。

![Epoch 20 Generated Images](kadai1_epoch_20.png)
*(Fig 1. Generatorによる生成画像 - Epoch 20)*

### 2. モーフィング生成 (Task 2: 4 $\to$ 9)
潜在空間（Latent Space）上で、「4」を生成する潜在変数 $z_4$ から、「9」を生成する潜在変数 $z_9$ へとベクトルを滑らかに変化（線形補間）させた結果である。

単なる画像のフェードアウト（重ね合わせ）ではなく、**「4」の形状が徐々に変形して「9」になっている**点に注目。これは、Generatorが単に画像を暗記しているのではなく、数字の形状の連続的な変化を学習できていることを示している。

![Morphing 4 to 9](kadai2.png)
*(Fig 2. 潜在変数の操作による「4」から「9」へのモーフィング)*

**補間式:**
$$z = (1 - \alpha) z_{start} + \alpha z_{end}$$
($\alpha$ を $0.0$ から $1.0$ まで変化させて生成)
